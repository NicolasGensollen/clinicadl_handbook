# -*- coding: utf-8 -*-
# ---
# jupyter:
#   jupytext:
#     text_representation:
#       extension: .py
#       format_name: percent
#       format_version: '1.5'
#       jupytext_version: 1.13.3
#   kernelspec:
#     display_name: Python 3
#     name: python3
# ---

# %%
# Uncomment this cell if running in Google Colab
# !pip install clinicadl==1.2.0
# !curl -k https://aramislab.paris.inria.fr/files/data/databases/tuto/dataOasis.tar.gz -o dataOasis.tar.gz
# !tar xf dataOasis.tar.gz
# %% [markdown]
# # Debug architecture search
# Previous sections were focusing on pre-built architectures available in
# ClinicaDL. These architectures were trained and validated on ADNI, and gave
# similar test results on ADNI, AIBL and OASIS. However, they might not be
# transferrable to other problems on other datasets using other modalities, and
# this is why may want to search for new architectures and hyperparameters.

# Looking for a new set of hyperparameters often means taking a lot of time
# training networks that are not converging. To avoid this pitfall, it is often
# advise to simplify the problem: focus on a subset of data / classification task
# that is more tractable than the one that is currently explored. This is the
# purpose of `clinicadl generate` which creates a set of synthetic, tractable data
# from real data to check that developed networks are working on this simple case
# before going further.

# <div class="alert alert-block alert-info">
# <b>Tractable data:</b><p>
#     In this notebook, we call tractable data a set of pairs of images and labels that can be easily classified. In ClinicaDL, tractable data is generated from real brain images and consist in creating two classes in which the intensitites of the left or the right part of the brain are decreased.</p>
#     <img src="images/generate.png" style="height: 200px;" alt="Schemes of synthetic tractable data">
# </div>

# If you ran the previous notebook, you must have a folder called
# `OasisCaps_example` in the current directory (Otherwise uncomment the next cell
# to download a local version of the necessary folders).
# %%
# !curl -k https://aramislab.paris.inria.fr/files/data/databases/tuto/OasisCaps2.tar.gz -o OasisCaps2.tar.gz
# !tar xf OasisCaps2.tar.gz
# %% [markdown]
# ## Generate tractable data

# Tractable data can be generated from real data with the following command line

# ```Text
# clinicadl generate trivial <caps_directory> <output_directory> --n_subjects <n_subjects>
# ```
# where:

# - `caps_directory` is the output folder containing the results in a [CAPS](http://www.clinica.run/doc/CAPS/) hierarchy.
# - `output_directory` is the folder where the synthetic CAPS is stored.
# - `n_subjects` is the number of subjects per label in the synthetic dataset. Default value: 300.

# ```{warning}
# `n_subjects` cannot be higher than the number of subjects in the initial
# dataset. Indeed in each synthetic class, a synthetic image derives from a real
# image.
# ```
# %% 
!clinicadl generate trivial OasisCaps_example --preprocessing t1-linear data/synthetic --n_subjects 4
# %% [markdown]
# ## Reproduce the tsv file system necessary to train

# In order to train a network, meta data must be organized in a file system
# generated by `clinicadl tsvtools`. For more information on the following
# commands, please read the section [Define your
# population](./label_extraction.ipynb).
# %%
# Get the labels AD and CN in separate files
# This command need a Bids as argument in order to create the missing_mods_directory and the merged.tsv file
# but when you already have it, you can give an empty folder and the path to the paths to the needed files.
# Be careful, the output of the command, labels.tsv is saved in the same folder as the bids.
!mkdir data/fake_bids
!clinicadl tsvtools get-labels data/fake_bids --missing_mods data/synthetic/missing_mods --merged_tsv data/synthetic/data.tsv --modality synthetic
# %%
# Split train and test data
!clinicadl tsvtools split data/labels.tsv --n_test 0.25 --subset_name test
# %%
# Split train and validation data in a 5-fold cross-validation
!clinicadl tsvtools kfold data/split/train.tsv --n_splits 3
# %% [markdown]
## Train a model on synthetic data

#Once data was generated and split it is possible to train a model using
#`clinicadl train` and evaluate its performance with `clinicadl interpret`. For
#more information on the following command lines please read the sections [Train
#your own models](./training.ipynb) and [Perfom classification using pretrained
#models](./inference.ipynb).

#The following command uses a pre-build architecture of ClinicaDL `Conv4_FC3`.
#You can also implement your own models by following the instructions of [this
#section](./training.ipynb).

# For now, there is a mistake when you generate data because tensors are extracted but the extract.json file
# is not extracted whereas this file is needed when you want to train a network. So it is needed to copy the 
# JSON file from the OasisCaps_example. 
# The ClinicaDL team is aware of thise problem and it will be solved in the next version.
# %%
# Train a network with synthetic data
!cp -r OasisCaps_example/tensor_extraction data/synthetic/tensor_extraction
!clinicadl train classification data/synthetic extract_T1linear_image.json data/split/3_fold data/synthetic_maps --architecture Conv4_FC3 --n_splits 3 --split 0 --no-gpu
# %% [markdown]
#As the number of images is very small (4 per class), we do not rely on the
#accuracy to select the model. Instead we evaluate the model which obtained the
#best loss.
# %% 
# Evaluate the network performance on the 2 test images
!clinicadl predict data/synthetic_maps test --caps_directory ./data/synthetic --participants_tsv ./data/split/test_baseline.tsv --selection_metrics "loss" --no-gpu
# %%
import pandas as pd

fold = 0

predictions = pd.read_csv("./data/synthetic_maps/split-%i/best-loss/test/test_image_level_prediction.tsv" % fold, sep="\t")
display(predictions)


metrics = pd.read_csv("./data/synthetic_maps/split-%i/best-loss/test/test_image_level_metrics.tsv" % fold, sep="\t")
display(metrics)
# %%
