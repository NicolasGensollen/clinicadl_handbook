{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f035f294",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# Uncomment this cell if running in Google Colab\n",
    "!pip install clinicadl==0.2.1\n",
    "!curl -k https://aramislab.paris.inria.fr/files/data/databases/tuto/dataOasis.tar.gz -o dataOasis.tar.gz\n",
    "!tar xf dataOasis.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c36b2e0",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "# Launch a random search\n",
    "The previous section focused on a way to debug non-automated architecture\n",
    "search. However, if you have enough computational power, you may want to launch\n",
    "an automated architecture search to save your time. This is the point of the\n",
    "random search method of clinicadl.\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Non-optimal result:</b><p>\n",
    "    A random search may allow to find a better performing network, however there is no guarantee that this is the best performing network.\n",
    "</div>\n",
    "\n",
    "This notebook relies on the synthetic data generated in the previous notebook.\n",
    "If you did not run it, uncomment the following cell to generate the\n",
    "corresponding dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e96a70",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# os.makedirs(\"data\", exist_ok=True)\n",
    "!curl -k https://aramislab.paris.inria.fr/files/data/databases/tuto/synthetic.tar.gz -o synthetic.tar.gz\n",
    "!tar xf synthetic.tar.gz -C data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2a693aa",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "## Define the hyperparameter space\n",
    "\n",
    "A random search is performed according to hyperparameters of the network that\n",
    "are sampled from a pre-defined space.\n",
    "For example, you may want your random network to have maximum 3\n",
    "fully-convolutional layers as you don't have enough memory to tackle more.\n",
    "\n",
    "This hyperparameter space is defined in a JSON file that must be written in your\n",
    "random search directory: `random_search.json`.\n",
    "\n",
    "The following function `generate_dict` generates a dictionnary that will be used\n",
    "to  `random_search.json` for this tutorial. To accelerate the training task we\n",
    "will use a single CNN on the default region of interet, the hippocampi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3de8278",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "def generate_dict(mode, caps_dir, tsv_path, preprocessing):\n",
    "    return {\n",
    "        \"caps_dir\": caps_dir,\n",
    "        \"tsv_path\": tsv_path,\n",
    "        \"diagnoses\": [\"AD\", \"CN\"],\n",
    "        \"preprocessing\": preprocessing,\n",
    "        \"mode\": mode,\n",
    "        \"network_type\": \"cnn\",\n",
    "        \n",
    "        \"epochs\": 30,\n",
    "        \"learning_rate\": [4, 6],\n",
    "        \n",
    "        \"n_convblocks\": [1, 5],               # Number of convolutional blocks\n",
    "        \"first_conv_width\": [8, 16, 32, 64],  # Number of channels in the first convolutional block\n",
    "        \"n_fcblocks\": [1, 3],                 # Number of (fully-connected + activation) layers\n",
    "        \n",
    "        \"selection_threshold\": [0.5, 1]       # Threshold at which a region is selected if its corresponding\n",
    "                                              # balanced accuracy is higher.\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e438e33",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "In this default dictionnary we set all the arguments that are mandatory for the\n",
    "random search. Hyperparameters for which a space is not defined will\n",
    "automatically have their default value in all cases.\n",
    "\n",
    "Hyperparameters can be sampled in 4 different ways:\n",
    "- choice samples one element from a list (ex: `first_conv_width`),\n",
    "- uniform draws samples from a uniform distribution over the interval [min, max] (ex: `selection_threshold`),\n",
    "- exponent draws x from a uniform distribution over the interval [min, max] and return $10^{-x}$ (ex: `learning_rate`),\n",
    "- randint returns an integer in [min, max] (ex: `n_conv_blocks`).\n",
    "\n",
    "In the default dictionnary, the learning rate will be sampled between $10^{-4}$\n",
    "and $10^{-6}$.\n",
    "\n",
    "This dictionnary is written as a JSON file in the `launch_dir` of the\n",
    "random-search.\n",
    "You can define differently other hyperparameters by looking at the\n",
    "[documentation](https://clinicadl.readthedocs.io/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "880140e6",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "mode = \"image\"\n",
    "caps_dir = \"data/synthetic\"\n",
    "tsv_path = \"data/synthetic/labels_list/train\"\n",
    "preprocessing = \"t1-linear\"\n",
    "\n",
    "os.makedirs(\"random_search\", exist_ok=True)\n",
    "default_dict = generate_dict(mode, caps_dir, tsv_path, preprocessing)\n",
    "# Add some changes here\n",
    "\n",
    "json = json.dumps(default_dict, skipkeys=True, indent=4)\n",
    "with open(os.path.join(\"random_search\", \"random_search.json\"), \"w\") as f:\n",
    "    f.write(json)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "365c076b",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "## Train & evaluate a random network\n",
    "Based on the hyperparameter space described in `random_search.json`, you will\n",
    "now be able to train a random network. To do so the following command can be\n",
    "run:\n",
    "\n",
    "```Text\n",
    "clinicadl random-search <launch_dir> <name> --n_splits <n_splits>\n",
    "```\n",
    "where:\n",
    "\n",
    "- `launch_dir` is the folder in which is located `random_search.json` and your future output jobs.\n",
    "- `output_directory` is the name of the folder of the job launched.\n",
    "- `n_splits` is the number of splits in the cross-validation procedure.\n",
    "\n",
    "Other arguments, linked to computational resources can be specified when\n",
    "launching the random training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9925c26f",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "!clinicadl random-search \"random_search\" \"test\" --n_splits 3 --split 0 -cpu -np 0 -v"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36c792ad",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "A new folder `test` has been created in `launch_dir`. As for any network trained\n",
    "with ClinicaDL it is possible to evaluate its performance on a test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a02358",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# Evaluate the network performance on the 2 test images\n",
    "!clinicadl classify ./data/synthetic ./data/synthetic/labels_list/test ./random_search/test 'test' --selection_metrics \"loss\" -cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae52a508",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "fold = 0\n",
    "\n",
    "predictions = pd.read_csv(\"./random_search/test/fold-%i/cnn_classification/best_loss/test_image_level_prediction.tsv\" % fold, sep=\"\\t\")\n",
    "display(predictions)\n",
    "\n",
    "\n",
    "metrics = pd.read_csv(\"./random_search/test/fold-%i/cnn_classification/best_loss/test_image_level_metrics.tsv\" % fold, sep=\"\\t\")\n",
    "display(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "561a3c85",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "## Analysis of the random network\n",
    "\n",
    "The architecture of the network can be retrieved from the `commandline.json`\n",
    "file in the folder corresponding to a random job.\n",
    "\n",
    "The architecture can be fully retrieved with 4 keys:\n",
    "- `convolutions` is a dictionnary describing each convolutional block,\n",
    "- `network_normalization` is the type of normalization layer used in covolutional blocks,\n",
    "- `n_fcblocks` is the number of fully-connected layers,\n",
    "- `dropout` is the dropout rate applied at the dropout layer.\n",
    "\n",
    "One convolutional block is described by the following values:\n",
    "- `in_channels` is the number of channels of the input (if set to null corresponds to the number of channels of the input data),\n",
    "- `out_channels` is the number of channels in the output of the convolutional block. It corresponds to 2 * `in_channels` except for the first channel chosen from `first_conv_width`, and if it becomes greater than `channels_limit`.\n",
    "- `n_conv` corresponds to the number of convolutions in the convolutional block,\n",
    "- `d_reduction` is the dimension reduction applied in the block.\n",
    "\n",
    "### Convolutional block - example 1\n",
    "\n",
    "Convolutional block dictionnary:\n",
    "```python\n",
    "{\n",
    "    \"in_channels\": 16,\n",
    "    \"out_channels\": 32,\n",
    "    \"n_conv\": 2,\n",
    "    \"d_reduction\": \"MaxPooling\"\n",
    "}\n",
    "```\n",
    "(`network_normalization` is set to `InstanceNorm`)\n",
    "\n",
    "Corresponding architecture drawing:\n",
    "<br>\n",
    "<img src=\"./images/convBlock1.png\" width=\"700\">\n",
    "<br>\n",
    "\n",
    "\n",
    "### Convolutional block - example 1\n",
    "\n",
    "Convolutional block dictionnary:\n",
    "```python\n",
    "{\n",
    "    \"in_channels\": 32,\n",
    "    \"out_channels\": 64,\n",
    "    \"n_conv\": 3,\n",
    "    \"d_reduction\": \"stride\"\n",
    "}\n",
    "```\n",
    "(`network_normalization` is set to `BatchNorm`)\n",
    "\n",
    "Corresponding architecture drawing:\n",
    "<br>\n",
    "<img src=\"./images/convBlock2.png\" width=\"700\">\n",
    "<br>\n",
    "\n",
    "A simple way to better visualize your random architecture is to construct it\n",
    "using `create_model` function from ClinicaDL. This function needs the list of\n",
    "options of the model stored in the JSON file as well as the size of the input. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "623d665d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torchsummary\n",
    "\n",
    "from clinicadl.tools.deep_learning.iotools import read_json\n",
    "from clinicadl.tools.deep_learning.models import create_model\n",
    "from clinicadl.tools.deep_learning.data import return_dataset, get_transforms\n",
    "\n",
    "from torchsummary import summary\n",
    "import argparse\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Read model options\n",
    "options = argparse.Namespace()\n",
    "model_options = read_json(options, json_path=\"random_search/test/commandline.json\")\n",
    "model_options.gpu = True\n",
    "\n",
    "# Find data input size\n",
    "_, transformations = get_transforms(mode, not model_options.unnormalize)\n",
    "dataset = return_dataset(mode, caps_dir, os.path.join(tsv_path, \"AD.tsv\"),\n",
    "                         preprocessing, transformations, model_options)\n",
    "input_size = dataset.size\n",
    "\n",
    "# Create model and print summary\n",
    "model = create_model(model_options, input_size)\n",
    "summary(model, input_size)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "encoding": "# -*- coding: utf-8 -*-",
   "main_language": "python"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
