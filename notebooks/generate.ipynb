{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a3a115a",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# Uncomment this cell if running in Google Colab\n",
    "!pip install clinicadl==0.2.1\n",
    "!curl -k https://aramislab.paris.inria.fr/files/data/databases/tuto/dataOasis.tar.gz -o dataOasis.tar.gz\n",
    "!tar xf dataOasis.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9de6f075",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "# Debug architecture search\n",
    "Previous sections were focusing on pre-built architectures available in\n",
    "ClinicaDL. These architectures were trained and validated on ADNI, and gave\n",
    "similar test results on ADNI, AIBL and OASIS. However, they might not be\n",
    "transferrable to other problems on other datasets using other modalities, and\n",
    "this is why may want to search for new architectures and hyperparameters.\n",
    "\n",
    "Looking for a new set of hyperparameters often means taking a lot of time\n",
    "training networks that are not converging. To avoid this pitfall, it is often\n",
    "advise to simplify the problem: focus on a subset of data / classification task\n",
    "that is more tractable than the one that is currently explored. This is the\n",
    "purpose of `clinicadl generate` which creates a set of synthetic, tractable data\n",
    "from real data to check that developed networks are working on this simple case\n",
    "before going further.\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Tractable data:</b><p>\n",
    "    In this notebook, we call tractable data a set of pairs of images and labels that can be easily classified. In ClinicaDL, tractable data is generated from real brain images and consist in creating two classes in which the intensitites of the left or the right part of the brain are decreased.</p>\n",
    "    <img src=\"images/generate.png\" style=\"height: 200px;\" alt=\"Schemes of synthetic tractable data\">\n",
    "</div>\n",
    "\n",
    "If you ran the previous notebook, you must have a folder called\n",
    "`OasisCaps_example` in the current directory (Otherwise uncomment the next cell\n",
    "to download a local version of the necessary folders)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2069095",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "!curl -k https://aramislab.paris.inria.fr/files/data/databases/tuto/OasisCaps2.tar.gz -o OasisCaps2.tar.gz\n",
    "!tar xf OasisCaps2.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19b25a9d",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "## Generate tractable data\n",
    "\n",
    "Tractable data can be generated from real data with the following command line\n",
    "\n",
    "```Text\n",
    "clinicadl generate trivial <caps_directory> <output_directory> --n_subjects <n_subjects>\n",
    "```\n",
    "where:\n",
    "\n",
    "- `caps_directory` is the output folder containing the results in a [CAPS](http://www.clinica.run/doc/CAPS/) hierarchy.\n",
    "- `output_directory` is the folder where the synthetic CAPS is stored.\n",
    "- `n_subjects` is the number of subjects per label in the synthetic dataset. Default value: 300.\n",
    "\n",
    "```{warning}\n",
    "`n_subjects` cannot be higher than the number of subjects in the initial\n",
    "dataset. Indeed in each synthetic class, a synthetic image derives from a real\n",
    "image.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "527885c0",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "!clinicadl generate trivial OasisCaps_example t1-linear data/synthetic --n_subjects 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d0c1295",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "## Reproduce the tsv file system necessary to train\n",
    "\n",
    "In order to train a network, meta data must be organized in a file system\n",
    "generated by `clinicadl tsvtool`. For more information on the following\n",
    "commands, please read the section [Define your\n",
    "population](./label_extraction.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d42c3d",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# Get the labels AD and CN in separate files\n",
    "!clinicadl tsvtool getlabels data/synthetic/data.tsv data/synthetic/missing_mods data/synthetic/labels_list --modality synthetic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a76578",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# Split train and test data\n",
    "!clinicadl tsvtool split data/synthetic/labels_list --n_test 0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb7dcbea",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# Split train and validation data in a 5-fold cross-validation\n",
    "!clinicadl tsvtool kfold data/synthetic/labels_list/train --n_splits 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b9a1fa4",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "# Train a model on synthetic data\n",
    "\n",
    "Once data was generated and split it is possible to train a model using\n",
    "`clinicadl train` and evaluate its performance with `clinicadl classify`. For\n",
    "more information on the following command lines please read the sections [Train\n",
    "your own models](./training.ipynb) and [Perfom classification using pretrained\n",
    "models](./inference.ipynb).\n",
    "\n",
    "The following command uses a pre-build architecture of ClinicaDL `Conv4_FC3`.\n",
    "You can also implement your own models by following the instructions of [this\n",
    "section](./training.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "018f6627",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# Train a network with synthetic data\n",
    "!clinicadl train roi cnn data/synthetic t1-linear data/synthetic/labels_list/train results/synthetic Conv4_FC3 --n_splits 3 --split 0 -v"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73881f60",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "As the number of images is very small (4 per class), we do not rely on the\n",
    "accuracy to select the model. Instead we evaluate the model which obtained the\n",
    "best loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c332b01",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# Evaluate the network performance on the 2 test images\n",
    "!clinicadl classify ./data/synthetic ./data/synthetic/labels_list/test ./results/synthetic 'test' --selection_metrics \"loss\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00fc307b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "fold = 0\n",
    "\n",
    "predictions = pd.read_csv(\"./results/synthetic/fold-%i/cnn_classification/best_loss/test_image_level_prediction.tsv\" % fold, sep=\"\\t\")\n",
    "display(predictions)\n",
    "\n",
    "\n",
    "metrics = pd.read_csv(\"./results/synthetic/fold-%i/cnn_classification/best_loss/test_image_level_metrics.tsv\" % fold, sep=\"\\t\")\n",
    "display(metrics)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "encoding": "# -*- coding: utf-8 -*-",
   "main_language": "python"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
