{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab5f930",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment this cell if running in Google Colab\n",
    "!pip install clinicadl==1.2.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5aa599c",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "# Generate synthetic dataset\n",
    "\n",
    "Previous sections were focusing on pre-built architectures available in\n",
    "ClinicaDL. These architectures were trained and validated on ADNI, and gave\n",
    "similar test results on ADNI, AIBL and OASIS. However, they might not be\n",
    "transferrable to other problems on other datasets using other modalities, and\n",
    "this is why may want to search for new architectures and hyperparameters.\n",
    "\n",
    "Looking for a new set of hyperparameters often means taking a lot of time\n",
    "training networks that are not converging. To avoid this pitfall, it is often\n",
    "advise to simplify the problem: focus on a subset of data / classification\n",
    "task that is more tractable than the one that is currently explored. This is\n",
    "the purpose of `clinicadl generate` which creates a set of synthetic,\n",
    "tractable data from real data to check that developed networks are working on\n",
    "this simple case before going further.\n",
    "\n",
    "With Clinicadl, you can generate three types of synthetic data sets for a binary classification depending on the option chosen: trivial, random or shepplogan.\n",
    "\n",
    "If you ran the previous notebook, you must have a folder called\n",
    "`CAPS_example` in the data_oasis directory (Otherwise uncomment the next cell\n",
    "to download a local version of the necessary folders)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b69bf04",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "!curl -k https://aramislab.paris.inria.fr/files/data/handbook_2023/data_oasis/CAPS_example.tar.gz -o oasisCaps.tar.gz\n",
    "!tar xf oasisCaps.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94586db4",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "## Generate trivial data\n",
    "\n",
    "Tractable data can be generated from real data with ClinicaDL. The command\n",
    "generates a synthetic dataset for a binary classification task from a\n",
    "CAPS-formatted dataset.  It produces a new CAPS containing trivial data which\n",
    "should be perfectly classified. Each label corresponds to brain images whose\n",
    "intensities of the right or the left hemisphere are strongly decreased.\n",
    "Trivial data are useful for debugging a framework: hyper parameters can be\n",
    "more easily tested as fewer data samples are required and convergence should\n",
    "be reached faster as the classification task is simpler.\n",
    "\n",
    "<img src=\"../images/generate_trivial.png\" alt=\"generate trivial\" style=\"height: 350px; margin: 10px; text-align: center;\">\n",
    "\n",
    "```{warning}\n",
    "You need to execute the `clinica run` and `clinicadl prepare-data` pipelines\n",
    "prior to running this task.  Moreover, the trivial option can synthesize at\n",
    "most a number of images per label that is equal to the total number of images\n",
    "in the input CAPS.\n",
    "```\n",
    "### Running the task\n",
    "\n",
    "```bash\n",
    "clinicadl generate trivial <caps_directory> <output_directory> --n_subjects <n_subjects>\n",
    "```\n",
    "where:\n",
    "\n",
    "- `caps_directory` is the output folder containing the results in a\n",
    "[CAPS](http://www.clinica.run/doc/CAPS/) hierarchy.\n",
    "- `output_directory` is the folder where the synthetic CAPS is stored.\n",
    "- `n_subjects` is the number of subjects per label in the synthetic dataset.\n",
    "Default value: 300.\n",
    "\n",
    "```{warning}\n",
    "`n_subjects` cannot be higher than the number of subjects in the initial\n",
    "dataset. Indeed in each synthetic class, a synthetic image derives from a real\n",
    "image.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c6104a",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "!clinicadl generate trivial data_oasis/CAPS_example data/synthetic --n_subjects 4 --preprocessing t1-linear"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "884d6f2c",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "### Reproduce the tsv file system necessary to train\n",
    "\n",
    "In order to train a network, meta data must be organized in a file system\n",
    "generated by `clinicadl tsvtools`. For more information on the following\n",
    "commands, please read the section [Define your\n",
    "population](./label_extraction.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ae562ff",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "#### Get the labels AD and CN.\n",
    "This command need a BIDS folder as argument in order to create the\n",
    "`missing_mods_directory` and the `merged.tsv` file but when you already have\n",
    "it, you can give an empty folder and the paths to the needed files.\n",
    "Be careful, the output of the command (`labels.tsv`) is saved in the same\n",
    "folder as the BIDS folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f9f428",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "!mkdir data/fake_bids\n",
    "!clinicadl tsvtools get-labels data/fake_bids --missing_mods data/synthetic/missing_mods --merged_tsv data/synthetic/data.tsv --modality synthetic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b935f77e",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# Split train and test data\n",
    "!clinicadl tsvtools split data/labels.tsv --n_test 0.25 --subset_name test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2589da85",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# Split train and validation data in a 5-fold cross-validation\n",
    "!clinicadl tsvtools kfold data/split/train.tsv --n_splits 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c780f26c",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "## Train a model on synthetic data\n",
    "\n",
    "Once data was generated and split it is possible to train a model using\n",
    "`clinicadl train` and evaluate its performance with `clinicadl interpret`. For\n",
    "more information on the following command lines please read the sections\n",
    "[Classification with a CNN on 2D slice](./training_classification.ipynb) and\n",
    "[Regression with 3D images](./training_regression.ipynb).\n",
    "\n",
    "The following command uses a pre-build architecture of ClinicaDL `Conv4_FC3`.\n",
    "You can also implement your own models by following the instructions of [this\n",
    "section](./training_custom.ipynb).\n",
    "\n",
    "If you failed to generate a trivial dataset, please uncomment the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd8475d",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "!curl -k https://aramislab.paris.inria.fr/clinicadl/files/handbook_2023/data/synthetic.tar.gz -o synthetic.tar.gz\n",
    "!tar xf synthetic.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d6df49",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# Prepare data (extraction of image tensors)\n",
    "!clinicadl prepare-data image data/synthetic t1-linear --extract_json extract_T1linear_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f6c461",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# Train a network with synthetic data\n",
    "!clinicadl train classification data/synthetic extract_T1linear_image data/split/3_fold data/synthetic_maps --architecture Conv4_FC3 --n_splits 3 --split 0 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d10d6f70",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "As the number of images is very small (4 per class), we do not rely on the\n",
    "accuracy to select the model. Instead we evaluate the model which obtained the\n",
    "best loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e611e3",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# Evaluate the network performance on the 2 test images\n",
    "!clinicadl predict data/synthetic_maps test --caps_directory ./data/synthetic --participants_tsv ./data/split/test_baseline.tsv --selection_metrics \"loss\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a2fa2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "fold = 0\n",
    "\n",
    "predictions = pd.read_csv(\"./data/synthetic_maps/split-%i/best-loss/test/test_image_level_prediction.tsv\" % fold, sep=\"\\t\")\n",
    "display(predictions)\n",
    "\n",
    "\n",
    "metrics = pd.read_csv(\"./data/synthetic_maps/split-%i/best-loss/test/test_image_level_metrics.tsv\" % fold, sep=\"\\t\")\n",
    "display(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c92c796a",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "## Generate random data\n",
    "\n",
    "This command generates a synthetic dataset for a binary classification task\n",
    "from a CAPS-formatted dataset. \n",
    "It produces a new CAPS containing random data which cannot be correctly\n",
    "classified. All the images from this dataset comes from the same image to\n",
    "which random noise is added. Then the images are randomly distributed between\n",
    "the two labels\n",
    "\n",
    "<img src=\"../images/generate_random.png\" alt=\"generate random\" style=\"height: 350px; margin: 10px; text-align: center;\">\n",
    "\n",
    "```{warning}\n",
    "You need to execute the `clinica run` and `clinicadl prepare-data` pipelines\n",
    "prior to running this task.  Moreover, the random option can synthesize as\n",
    "many images as wanted with only one input image.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1751c7a6",
   "metadata": {},
   "source": [
    "###Running the task\n",
    "```bash\n",
    "clinicadl generate random <caps_directory> <generated_caps_directory> \n",
    "```\n",
    "where:\n",
    "\n",
    "- `caps_directory` is the output folder containing the results in a [CAPS](http://www.clinica.run/doc/CAPS/) hierarchy.\n",
    "- `generated_caps_directory` is the folder where the synthetic CAPS is stored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f8ef2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!clinicadl generate random data_oasis/CAPS_example data/CAPS_random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43849231",
   "metadata": {},
   "source": [
    "The command generates 3D images of same size as the input images formatted as\n",
    "NIfTI files. Then the `clinicadl prepare-data` command must be run to use the\n",
    "synthetic data with ClinicaDL. Results are stored in the same folder hierarchy\n",
    "as the input folder."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d0516e8",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "## Generate Shepp-Logan data\n",
    "\n",
    "This command is named after the Shepp-Logan phantom, a standard image to test\n",
    "image reconstruction algorithms.\n",
    "It creates three subtypes of 2D images distributed between two labels. These\n",
    "three subtypes can be separated according to the top (framed in blue) and\n",
    "bottom (framed in orange) regions: \n",
    "- subtype 0: Top and Bottom regions are of maximum size, \n",
    "- subtype 1: Top region has its maximum size but Bottom is atrophied, \n",
    "- subtype 2: Bottom region has its maximum size but Top is atrophied.\n",
    "\n",
    "<img src=\"../images/generate_shepplogan.png\" alt=\"generate shepplogan\" style=\"height: 350px; margin: 10px; text-align: center;\">\n",
    "\n",
    "These three subtypes are spread between two labels which mimic the binary\n",
    "classification between Alzheimer's disease patients (AD) with heterogeneous\n",
    "phenotypes and cognitively normal participants (CN). Default distributions are\n",
    "the following:\n",
    "\n",
    "| subtype |   0  |   1  |   2  |\n",
    "|---------|------|------|------|\n",
    "|    AD   |  5%  | 85%  | 10%  |\n",
    "|    CN   | 100% |  0%  |  0%  |\n",
    "\n",
    "The CN label is homogeneous, while the AD label is composed of a typical\n",
    "subtype (1), an atypical subtype (2) and normal looking images (0)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca52d569",
   "metadata": {},
   "source": [
    "### Running the task\n",
    "```Text\n",
    "clinicadl generate shepplogan <generated_caps_directory> \n",
    "```\n",
    "where:\n",
    "- `generated_caps_directory` is the folder where the synthetic CAPS is stored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5aa12df",
   "metadata": {},
   "outputs": [],
   "source": [
    "!clinicadl generate shepplogan data/CAPS_shepplogan --n_subjects 3"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "encoding": "# -*- coding: utf-8 -*-",
   "main_language": "python"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
