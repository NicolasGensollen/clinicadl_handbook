{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e853e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ---\n",
    "# jupyter:\n",
    "#   jupytext:\n",
    "#     text_representation:\n",
    "#       extension: .py\n",
    "#       format_name: percent\n",
    "#       format_version: '1.5'\n",
    "#       jupytext_version: 1.7.1\n",
    "#   kernelspec:\n",
    "#     display_name: Python 3\n",
    "#     name: python3\n",
    "# ---‚àè"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b362e1d4",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "## How to use `clinicadl train`\n",
    "\n",
    "ClinicaDL is able to train networks using different kind of inputs (3D images,\n",
    "3D patches or 2D slices).\n",
    "\n",
    "A single network can learnt diiferent task: *classification*, *reconstruction*\n",
    "and *regression*.\n",
    "\n",
    "All information necessary to reproduce the train (network architecture, hyperparameters, weights)\n",
    "is stored in the MAPS."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "415603c5",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "## Using `clinicadl train`\n",
    "\n",
    "Training a neural network requires a lot of inputs from the user. For\n",
    "clinicadl the main inputs are:\n",
    "* The kind of task to train (*classification*, *reconstruction* and\n",
    "  *regression*).\n",
    "* The folder containing the input images in CAPS format.\n",
    "* A file containing information on the preprocessing  `PREPROCESSING_JSON`.\n",
    "* A folder wiht files in TSV format to define where the train and validation are stored.\n",
    "* A folder to the path where the MAPS will be stored.\n",
    "\n",
    "Multiple options can be entered by using the option `-c, --config_file`, a\n",
    "file in format TOML, a human-readable format.\n",
    "\n",
    "The help for the `clinicadl train` functionality:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de75c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "! clinicadl train -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb6ccf8",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# Download the data\n",
    "#! wget --no-check-certificate --progress=bar:force -O ../data/RandomCaps.tar.gz https://aramislab.paris.inria.fr/files/data/databases/tuto2/RandomCaps.tar.gz\n",
    "! tar xf ../data/RandomCaps.tar.gz -C ../data/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cff1490e",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "## Example 1: training using the whole image\n",
    "Lets suposse that we want to train a network of preprocessed images using\n",
    "slices.\n",
    "Our images comes from a synthetic dataset containing images with random noise,\n",
    "obtained with `clinicadl generate`. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce8dec1f",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "The configuration file `train_cnofig.toml`\n",
    "```[toml]\n",
    "# Config file for tutotiel\n",
    "[Cross_validation]\n",
    "n_splits = 2\n",
    "split = []\n",
    "\n",
    "[Classification]\n",
    "label = \"sex\"\n",
    "\n",
    "[Optimization]\n",
    "epochs = 1\n",
    "\n",
    "[Data]\n",
    "multi_cohort = false\n",
    "diagnoses = [\"CN\"]\n",
    "```\n",
    "Mani other variables can be configured, [see the\n",
    "documentation](https://clinicadl.readthedocs.io/en/stable/Train/Introduction/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cef23cb",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "! clinicadl train classification ../data/caps_v2021 extract_image_t1_linear.json ../data/labels_list/train ../data/out -c ../data/train_config.toml "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "307beba5",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "## Example 2: training using only slices of the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc3fe9a",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "! clinicadl train classification ../data/random_example extract_slice.json ../data/labels_list/train ../data/out -c ../data/train_config.toml "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27fe3d87",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "## Visualization of the `MAPS`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4912d5e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "! tree -L 4 ../data/out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db8dd8c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
