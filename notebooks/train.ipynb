{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8782ab17",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ---\n",
    "# jupyter:\n",
    "#   jupytext:\n",
    "#     text_representation:\n",
    "#       extension: .py\n",
    "#       format_name: percent\n",
    "#       format_version: '1.5'\n",
    "#       jupytext_version: 1.7.1\n",
    "#   kernelspec:\n",
    "#     display_name: Python 3\n",
    "#     name: python3\n",
    "# ---‚àè"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb90d673",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "## How to use `clinicadl train`\n",
    "\n",
    "ClinicaDL is able to train networks using different kind of inputs (3D images,\n",
    "3D patches or 2D slices).\n",
    "\n",
    "A single network can learnt diiferent task: *classification*, *reconstruction*\n",
    "and *regression*.\n",
    "\n",
    "All information necessary to reproduce the train (network architecture, hyperparameters, weights)\n",
    "is stored in the MAPS."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85b81281",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "## Using `clinicadl train`\n",
    "\n",
    "Training a neural network requires a lot of inputs from the user. For\n",
    "clinicadl the main inputs are:\n",
    "* The kind of task to train (*classification*, *reconstruction* and\n",
    "  *regression*).\n",
    "* The folder containing the input images in CAPS format.\n",
    "* A file containing information on the preprocessing  `PREPROCESSING_JSON`.\n",
    "* A folder wiht files in TSV format to define where the train and validation are stored.\n",
    "* A folder to the path where the MAPS will be stored.\n",
    "\n",
    "Multiple options can be entered by using the option `-c, --config_file`, a\n",
    "file in format TOML, a human-readable format.\n",
    "\n",
    "The help for the `clinicadl train` functionality:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e1b498b",
   "metadata": {},
   "outputs": [],
   "source": [
    "! clinicadl train -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be4ee9cc",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# Download the data\n",
    "! wget --no-check-certificate --progress=bar:force -O ../data/RandomCaps.tar.gz https://aramislab.paris.inria.fr/files/data/databases/tuto2/RandomCaps.tar.gz\n",
    "! tar xf ../data/RandomCaps.tar.gz -C ../data/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbaf7f2d",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "## Example 1: training uning the whole image\n",
    "Lets suposse that we want to train a network of preprocessed images using slices:\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1373635",
   "metadata": {},
   "outputs": [],
   "source": [
    "! clinicadl train classification ../data/random_example extract_slice.json ../data/labels_list ../data/out -c ../data/train_config.toml "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "067c8344",
   "metadata": {},
   "source": [
    "## Example 2: training using only slices of the image"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
