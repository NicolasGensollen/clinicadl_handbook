{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f80032",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# Uncomment this cell if running in Google Colab\n",
    "!pip install clinicadl==0.2.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88ab4d83",
   "metadata": {},
   "source": [
    "# Generate saliency maps on trained networks\n",
    "\n",
    "Explaining black-box models can be useful to better understand their behaviour.\n",
    "For more information on this complex topic, we highly recommend the review of\n",
    "[Xie et al.](http://arxiv.org/abs/2004.14545).\n",
    "\n",
    "In ClinicaDL, the most basic method of interpretability was implemented:\n",
    "[gradients visualization](https://arxiv.org/pdf/1312.6034.pdf) (sometimes called\n",
    "saliency maps). This method shows how the voxel intensities of an input image\n",
    "should be modified in order to increase the value of a particular output node.\n",
    "Here the output nodes correspond to a label: the first one represents AD whereas\n",
    "the second represents CN.\n",
    "\n",
    "This method can be performed on an individual or on a group fashion (in this\n",
    "case it will be the mean value of all the individual saliency maps in the\n",
    "group)."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "encoding": "# -*- coding: utf-8 -*-",
   "main_language": "python"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
