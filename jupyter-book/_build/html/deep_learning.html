
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Deep learning classification: application to neuroimaging &#8212; Deep Learning Classification from brain MRI</title>
    
  <link href="_static/css/theme.css" rel="stylesheet">
  <link href="_static/css/index.ff1ffe594081f20da1ef19478df9384b.css" rel="stylesheet">

    
  <link rel="stylesheet"
    href="_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-book-theme.css?digest=c3fdc42140077d1ad13ad2f1588a4309" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="_static/tabs.css" />
    <link rel="stylesheet" type="text/css" href="_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="_static/js/index.be7d3bbb2ef33a8344ce.js">

    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="_static/sphinx-book-theme.d59cb220de22ca1c485ebbdc042f0030.js"></script>
    <script async="async" src="https://unpkg.com/thebe@0.5.1/lib/index.js"></script>
    <script>
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="_static/sphinx-thebe.js"></script>
    <link rel="canonical" href="https://aramislab.paris.inria.fr/clinicadl/tuto/deep_learning.html" />
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Organization of neuroimaging data: the Brain Imaging Data Structure (BIDS)" href="notebooks/preprocessing.html" />
    <link rel="prev" title="Clinical context: Alzheimerâ€™s disease" href="clinical.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
<script async="" src="https://www.google-analytics.com/analytics.js"></script>
<script>
                        window.ga = window.ga || function () {
                            (ga.q = ga.q || []).push(arguments) };
                        ga.l = +new Date;
                        ga('create', 'UA-173464732-1', 'auto');
                        ga('set', 'anonymizeIp', true);
                        ga('send', 'pageview');
                    </script>

  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="_static/logoAramis.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Deep Learning Classification from brain MRI</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Background
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="clinical.html">
   Clinical context
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   Deep learning classification
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  The basics
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="notebooks/preprocessing.html">
   Prepare your neuroimaging data
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="notebooks/inference.html">
   Perform classification using pretrained models
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Going further
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="notebooks/tsvtools.html">
   Define your population
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="notebooks/training.html">
   Train your own models
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="notebooks/interpretability.html">
   Interpret trained models
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Architecture search
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="notebooks/generate.html">
   Debug non-automated search
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="notebooks/random_search.html">
   Random search
  </a>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="_sources/deep_learning.md"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.md</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
                onclick="printPdf(this)" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        <a class="repository-button"
            href="https://github.com/aramis-lab/tuto_clinicadl"><button type="button" class="btn btn-secondary topbarbtn"
                data-toggle="tooltip" data-placement="left" title="Source repository"><i
                    class="fab fa-github"></i>repository</button></a>
        <a class="issues-button"
            href="https://github.com/aramis-lab/tuto_clinicadl/issues/new?title=Issue%20on%20page%20%2Fdeep_learning.html&body=Your%20issue%20content%20here."><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Open an issue"><i class="fas fa-lightbulb"></i>open issue</button></a>
        <a class="edit-button" href="https://github.com/aramis-lab/tuto_clinicadl/edit/main/jupyter-book/deep_learning.md"><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Edit this page"><i class="fas fa-pencil-alt"></i>suggest edit</button></a>
    </div>
</div>

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show noprint">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contents
            </div>
            <nav id="bd-toc-nav" aria-label="Page">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#common-network-layers">
   Common network layers
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#convolution">
     Convolution
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#batch-normalization">
     Batch normalization
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#activation-function-leaky-relu">
     Activation function (Leaky ReLU)
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#pooling-function">
     Pooling function
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#dropout">
     Dropout
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#fully-connected">
     Fully-connected
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#tasks-architectures">
   Tasks &amp; architectures
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#classification-with-a-cnn">
     Classification with a CNN
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#autoencoder-pretraining">
     Autoencoder pretraining
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#neuroimaging-inputs">
   Neuroimaging inputs
  </a>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Deep learning classification: application to neuroimaging</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#common-network-layers">
   Common network layers
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#convolution">
     Convolution
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#batch-normalization">
     Batch normalization
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#activation-function-leaky-relu">
     Activation function (Leaky ReLU)
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#pooling-function">
     Pooling function
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#dropout">
     Dropout
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#fully-connected">
     Fully-connected
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#tasks-architectures">
   Tasks &amp; architectures
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#classification-with-a-cnn">
     Classification with a CNN
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#autoencoder-pretraining">
     Autoencoder pretraining
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#neuroimaging-inputs">
   Neuroimaging inputs
  </a>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            
              <div>
                
  <div class="tex2jax_ignore mathjax_ignore section" id="deep-learning-classification-application-to-neuroimaging">
<h1>Deep learning classification: application to neuroimaging<a class="headerlink" href="#deep-learning-classification-application-to-neuroimaging" title="Permalink to this headline">Â¶</a></h1>
<p>Deep learning is an ill-defined term that may refer to many different concepts. In this notebook,
deep learning designate methods used to optimize a <strong>network</strong> that executes a task whose success
is quantified by a <strong>loss function</strong>. This optimization or learning process is based on a <strong>dataset</strong>,
whose samples are used to optimize the parameters of the network.</p>
<p>Deep learning networks are a succession of functions (called <strong>layers</strong>) which transform their inputs in outputs
(called <strong>feature maps</strong>). There are two types of layers:</p>
<ul class="simple">
<li><p>Layers including learnable parameters that will be updated to improve the loss (for example convolutions).</p></li>
<li><p>Layers with fixed behaviour during the whole training process (for example pooling or activation functions).</p></li>
</ul>
<p>Indeed, some characteristics are not modified during the training of the networks.
These components are fixed prior to training according to <strong>hyperparameters</strong>,
such as the number of layers or intrinsic characteristics of layers.
One of the main difficulties of deep learning is often not to train the networks,
but to find good hyperparameters that will be adapted to the task and the dataset.
This problem gave birth to a research field called <strong>Neural Architecture Search</strong> (NAS).
A basic method of NAS, the random search, is the theme of one of the last <a class="reference internal" href="notebooks/random_search.html"><span class="doc std std-doc">notebooks</span></a>.</p>
<details>
<summary>
Why deep ?
</summary>
Originally the term deep was used to differentiate shallow networks, with only one layer, 
from those with two layers are more. Today the distinction is not really useful anymore as most of the networks 
have way more than two layers!
</details>
<div class="section" id="common-network-layers">
<h2>Common network layers<a class="headerlink" href="#common-network-layers" title="Permalink to this headline">Â¶</a></h2>
<p>In a deep learning network every function is called a layer though the operations layers perform are very different.
You will find below a summary of the layers composing the architectures used in the following sections of this tutorial.</p>
<div class="section" id="convolution">
<h3>Convolution<a class="headerlink" href="#convolution" title="Permalink to this headline">Â¶</a></h3>
<p>The aim of a convolution layer is to learn a set of filters (or kernels) which capture useful
patterns in the data distribution. These filters parse the input feature map using translations:</p>
<img src="https://drive.google.com/uc?id=166EuqiwIZkKPMOlVzA-v5WemJE2tDCES" style="height: 200px;">
<p>A convolution layer captures local patterns that are limited to the size of its filters.
However, a succession of several convolutions allows increasing the <strong>receptive field</strong>,
i.e. the size of the region used in the input image to compute one value of the output feature map.
In this way, the first layer of the network will capture local patterns in the image (edges, homogeneous regions)
and the next one will assemble these patterns to form more and more complex patterns
(gyri and sulci, then regions of the brain).</p>
</div>
<div class="section" id="batch-normalization">
<h3>Batch normalization<a class="headerlink" href="#batch-normalization" title="Permalink to this headline">Â¶</a></h3>
<p>This layer learns to normalize feature maps according to
(<a class="reference external" href="https://arxiv.org/abs/1502.03167">Ioffe &amp; Szegedy, 2015</a>).
Adding this layer to a network may accelerate the training procedure.</p>
</div>
<div class="section" id="activation-function-leaky-relu">
<h3>Activation function (Leaky ReLU)<a class="headerlink" href="#activation-function-leaky-relu" title="Permalink to this headline">Â¶</a></h3>
<p>To introduce non-linearity in the model, an activation function is introduced after the convolutions
and fully-connected layers. Without activation functions, the network would only learn linear combinations!</p>
<p>Many activation functions have been proposed to solve deep learning problems.
In the architectures implemented in <code class="docutils literal notranslate"><span class="pre">clinicadl</span></code> the activation function is Leaky ReLU:</p>
<img src="https://sefiks.com/wp-content/uploads/2018/02/prelu.jpg?w=600" style="height: 200px;">
</div>
<div class="section" id="pooling-function">
<h3>Pooling function<a class="headerlink" href="#pooling-function" title="Permalink to this headline">Â¶</a></h3>
<p>Pooling layers reduce the size of their input feature maps.
Their structure is very similar to the convolutional layer: a kernel with a defined size and stride is
passing through the input. However there are no learnable parameters in this layer,
the kernel outputting the maximum value of the part of the feature map it covers.</p>
<p>Here is an example in 2D of the standard layer of pytorch <code class="docutils literal notranslate"><span class="pre">nn.MaxPool2d</span></code>:</p>
<img src="https://drive.google.com/uc?id=1qh9M9r9mfpZeSD1VjOGQAl8zWqBLmcKz" style="height: 200px;">
<p>The last column may not be used depending on the size of the kernel/input and stride value.
To avoid this, pooling layers with adaptative padding were implemented in <code class="docutils literal notranslate"><span class="pre">clinicadl</span></code>
to exploit information from the whole feature map.</p>
<img src="https://drive.google.com/uc?id=14R_LCTiV0N6ZXm-3wQCj_Gtc1LsXdQq_" style="height: 200px;">
</div>
<div class="section" id="dropout">
<h3>Dropout<a class="headerlink" href="#dropout" title="Permalink to this headline">Â¶</a></h3>
<p>Proposed by (<a class="reference external" href="http://jmlr.org/papers/volume15/srivastava14a/srivastava14a.pdf">Srivastava et al., 2014</a>),
dropout layers literally drop out a fixed proportion of the input values (i.e. replace their value by 0).
This behavior is enabled during training to limit overfitting, then it is disabled during evaluation to obtain
the best possible prediction.</p>
</div>
<div class="section" id="fully-connected">
<h3>Fully-connected<a class="headerlink" href="#fully-connected" title="Permalink to this headline">Â¶</a></h3>
<p>Contrary to convolutions in which relationships between values are studied locally,
fully-connected layers look for a global linear combination between all the input values
(hence the term fully-connected).
In convolutional neural networks they are often used at the end of the architecture
to reduce the final feature maps to a number of nodes equal to the number of classes in the dataset.</p>
</div>
</div>
<div class="section" id="tasks-architectures">
<h2>Tasks &amp; architectures<a class="headerlink" href="#tasks-architectures" title="Permalink to this headline">Â¶</a></h2>
<p>Deep learning methods have been used to learn many different tasks such as classification, dimension reduction,
data synthesisâ€¦ In this notebook we focus on the <strong>classification of images</strong> using
<strong>convolutional neural networks</strong> (CNN).</p>
<p>To successfully learn a task, a network needs to analyze a large number of labeled samples.
In neuroimaging, these samples are costly to acquire and thus their number is limited.
As deep learning models tend to easily overfit when trained on small samples due to the large number of learnt
parameters, different strategies have been developed to alleviate overfitting. These strategies include dropout,
data augmentation or adding a weight decay in the optimizer. Another technique seen in this notebook consists
in transferring weights learnt by an <strong>autoencoder</strong>. Indeed this network can learn patterns representative of
the dataset in a self-supervised manner, hence it does not need labels and can be trained on all samples available.</p>
<div class="section" id="classification-with-a-cnn">
<h3>Classification with a CNN<a class="headerlink" href="#classification-with-a-cnn" title="Permalink to this headline">Â¶</a></h3>
<p>A CNN takes as input an image and outputs a vector of size <code class="docutils literal notranslate"><span class="pre">C</span></code>,
corresponding to the number of different labels existing in the dataset.
More precisely, this vector contains a value for each class that is often interpreted (after some processing)
as the probability that the input image belongs to the corresponding class.
Then, the prediction of the CNN for a given image corresponds to the class with the highest probability
in the output vector.</p>
<p>The cross-entropy loss is used to quantify the error made by the network during the training process,
which becomes null if the network outputs 100% probability for the true class.</p>
<p>There are no rules regarding the architectures of CNNs, except that they contain convolution and activation layers.
In <code class="docutils literal notranslate"><span class="pre">clinicadl</span></code>, other layers such as pooling, batch normalization, dropout and fully-connected layers are also used.</p>
<figure>
  <img src="images/CNN_architecture.png" alt="CNN architecture" style="height: 300px; margin: 10px; text-align: center;">
    <figcaption><i>Example of a CNN architecture</i></figcaption>
</figure>
</div>
<div class="section" id="autoencoder-pretraining">
<h3>Autoencoder pretraining<a class="headerlink" href="#autoencoder-pretraining" title="Permalink to this headline">Â¶</a></h3>
<p>An autoencoder learns to reconstruct data given as input. It is composed of two parts:</p>
<ul class="simple">
<li><p>the <code class="docutils literal notranslate"><span class="pre">encoder</span></code> which reduces the dimensionality of the input to a smaller feature map: the code,</p></li>
<li><p>the <code class="docutils literal notranslate"><span class="pre">decoder</span></code> which reconstructs the input based on the code.</p></li>
</ul>
<p>The mean squared error is used to evaluate the difference between the input and its reconstruction.</p>
<p>There are many paradigms associated to autoencoders, but here we will only focus on a specific case
that allows the obtention of weights that can be transferred to a CNN. In <code class="docutils literal notranslate"><span class="pre">clinicadl</span></code>,
autoencoders are designed based on a CNN:</p>
<ul class="simple">
<li><p>the <code class="docutils literal notranslate"><span class="pre">encoder</span></code> corresponds to the convolutional layers of the CNN,</p></li>
<li><p>the <code class="docutils literal notranslate"><span class="pre">decoder</span></code> is composed of the transposed version of the operations used in the encoder.</p></li>
</ul>
<p>After training the autoencoder, the weights in its encoder can be copied in the convolutional layers
of a CNN to initialize it. This can improve its performance as the autoencoder has already learnt
patterns characterizing the data distribution.</p>
<figure>
  <img src="images/autoencoder_architecture.png" alt="CNN architecture" style="height: 350px; margin: 10px; text-align: center;">
    <figcaption><i>Autoencoder derived from the previous CNN architecture</i></figcaption>
</figure>
</div>
</div>
<div class="section" id="neuroimaging-inputs">
<h2>Neuroimaging inputs<a class="headerlink" href="#neuroimaging-inputs" title="Permalink to this headline">Â¶</a></h2>
<p>A CNN takes as input an image and learns to associate a label to it.
However, most deep learning methods were originally developed for natural images which are two dimensional,
whereas brain images are volumesâ€¦</p>
<p>The layers seen before (convolutions, pooling) were adapted to work on 3D feature maps making
possible the classification of MR volumes. However, it is also possible to use as inputs subparts of the image:</p>
<ul class="simple">
<li><p>2D slices extracted from the volume along a particular axis,</p></li>
<li><p>3D patches, i.e. smaller 3D volumes extracted from the full image with a given size and stride,</p></li>
<li><p>Regions of Interest (ROI) defined by a neuroanatomical atlas. They can be given as volumes,
using a bounding box that covers the ROI or by segmenting the ROI and setting the voxels that do not belong
to it to 0. It is also possible to give slices of these regions.</p></li>
</ul>
<p>While the aim of 2D slices and 3D patches is to cover the whole brain,
selecting a particular ROI requires prior knowledge of the disease studied.
In the case of Alzheimerâ€™s disease, the most affected region for most patients is the hippocampus,
thus this region has been used in several studies.</p>
<img src="images/neuroimaging_inputs.png" alt="Neuroimaging inputs" style="height: 350px; margin: 10px; text-align: center;">
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            
                <!-- Previous / next buttons -->
<div class='prev-next-area'> 
    <a class='left-prev' id="prev-link" href="clinical.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">Clinical context: Alzheimerâ€™s disease</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="notebooks/preprocessing.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Organization of neuroimaging data: the Brain Imaging Data Structure (BIDS)</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            
        </div>
    </div>
    <footer class="footer">
  <p>
    
      By The Aramis Team<br/>
    
        &copy; Copyright 2020-2022.<br/>
  </p>
</footer>
</main>


      </div>
    </div>
  
  <script src="_static/js/index.be7d3bbb2ef33a8344ce.js"></script>

  </body>
</html>